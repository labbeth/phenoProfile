# Pheno Profile

This project provides a complete pipeline for learning dense patient embeddings from a binary patient Ã— HPO phenotype matrix, using multiple embedding methods:

* Hyperbolic embeddings (FrÃ©chet mean, Einstein midpoint)

* Linear factorization (Truncated SVD, NMF)

* Non-linear autoencoder

* Optional: hybrid methods (planned)

The goal is to compare how different mathematical representations capture phenotypic similarity across patients, and how well these representations align with ground-truth diagnoses.

## ğŸŒ³ Project structure

```
project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ binary_matrix.csv              # Patient Ã— phenotype binary matrix
â”‚   â”œâ”€â”€ diagnosis_synthetic.csv        # Synthetic patient diagnoses (generated)
â”‚   â”œâ”€â”€ hpo_embeddings.npy             # Precomputed HPO hyperbolic embeddings
â”‚   â”œâ”€â”€ embeddings_metadata.pkl        # Contains metadata, including ordered HPO IDs
â”‚   â””â”€â”€ [...]                          # Other data files
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ patient_embeddings_all_methods.npz   # Final consolidated embedding file
â”‚   â”œâ”€â”€ patient_embedding_stats.csv          # Stats describing embeddings
â”‚   â”œâ”€â”€ evaluation_results.csv               # Cluster evaluation metrics
â”‚   â”œâ”€â”€ plots/
â”‚   â”‚   â”œâ”€â”€ tsne_frechet_unw.png
â”‚   â”‚   â”œâ”€â”€ tsne_einstein_unw.png
â”‚   â”‚   â””â”€â”€ ... (t-SNE visualizations)
â”‚   â””â”€â”€ [...]
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ compute_patient_embeddings_all_methods.py   # Generates all embeddings
â”‚   â”œâ”€â”€ evaluate_patient_embeddings.py               # Evaluates clustering vs diagnosis
â”‚   â”œâ”€â”€ train_patient_autoencoder.py                 # Trains AE + stores embeddings
â”‚   â”œâ”€â”€ generate_synthetic_diagnosis_file.py         # Creates fake diagnosis file
â”‚   â””â”€â”€ [...]
â”‚
â””â”€â”€ README.md
```

## ğŸ§© Core Concepts

### 1. Patient Ã— Phenotype Matrix

The project starts from a CSV where:

* Rows = patients

* Columns = HPO codes

* Values = 1/0 (phenotype present/absent)

The matrix is automatically aligned with the HPO embeddings using metadata["hpo_ids"] (the first column of the CSV should be IDs)


### 2. HPO Hyperbolic Embeddings

Using a pretrained HierarchyTransformers hyperbolic model, each phenotype has a dense embedding in the PoincarÃ© ball. These embeddings encode:

* hierarchical depth

* semantic similarity

* taxonomic relationships

### 3. Patient Embeddings (6 methods)

For each patient, we derive a dense embedding using:

#### Data-driven approaches

Linear and non-linear methods using only the binary Patient Ã— Phenotype matrix.

* Truncated SVD
* NMF (Non-negative Matrix Factorization)
* Autoencoder

#### Knowledge-based approaches

Non-linear based on HPO hyperbolic embeddings applied to the binary Patient Ã— Phenotype matrix. 

Unweighted methods treat each phenotype equally, while IC (Information-Content) methods weight each phenotype based on its relative discriminative importance within all the patients.

* FrÃ©chet mean (unweighted)
* Einstein midpoint (unweighted)
* FrÃ©chet mean (IC-weighted)
* Einstein midpoint (IC-weighted)

All resulting embeddings are stored in a single file:
```text
output/patient_embeddings_all_methods.npz
```

## ğŸ§ª Evaluation Workflow

The evaluation script compares each embedding method using:

### 1. Clustering performance

Using KMeans (k = number of diagnosis classes):

* Adjusted Rand Index (ARI)
* Normalized Mutual Information (NMI)

These compare unsupervised clusters to the (synthetic or real) diagnosis labels.

### 2. Intrinsic cluster quality

Independent of diagnoses:

* Silhouette score
* Daviesâ€“Bouldin index

These assess how â€œclusterableâ€ the embedding space is.

### 3. Visual inspection

Optional t-SNE projections for each embedding:

```
output/plots/tsne_<method>.png
```

## ğŸ›  How to Run the Pipeline